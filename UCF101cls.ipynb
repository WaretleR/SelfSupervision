{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from timesformer_pytorch import TimeSformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucfPath = 'D:/Files/Datasets/UCF-101'\n",
    "framesPerVideo = 10\n",
    "maxVideoPerClass = 5\n",
    "numEpochs = 10\n",
    "batchSize = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTimeSformer(TimeSformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        num_frames,\n",
    "        num_classes,\n",
    "        image_size = 320,\n",
    "        patch_size = 16,\n",
    "        channels = 3,\n",
    "        depth = 12,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.\n",
    "    ):\n",
    "        super().__init__(dim = dim, \n",
    "                         num_frames = num_frames, \n",
    "                         num_classes = num_classes, \n",
    "                         image_size = image_size, \n",
    "                         patch_size = patch_size,\n",
    "                         channels = channels, \n",
    "                         depth = depth,\n",
    "                         heads = heads,\n",
    "                         dim_head = dim_head,\n",
    "                         attn_dropout = attn_dropout,\n",
    "                         ff_dropout = ff_dropout)\n",
    "        self.to_out = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(dim),\n",
    "            torch.nn.Linear(dim, num_classes),\n",
    "            #torch.nn.Softmax(num_classes)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvancedTimeSformer(\n",
      "  (to_patch_embedding): Linear(in_features=768, out_features=64, bias=True)\n",
      "  (pos_emb): Embedding(4001, 64)\n",
      "  (layers): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (1): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_out): Sequential(\n",
      "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=64, out_features=101, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AdvancedTimeSformer(\n",
    "    dim = 64,\n",
    "    image_size = 320,\n",
    "    patch_size = 16,\n",
    "    num_frames = framesPerVideo,\n",
    "    num_classes = 101,\n",
    "    depth = 4,\n",
    "    heads = 4,\n",
    "    dim_head = 16,\n",
    "    attn_dropout = 0.1,\n",
    "    ff_dropout = 0.1\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process class ApplyEyeMakeup\n",
      "Process class ApplyLipstick\n",
      "Process class Archery\n",
      "Process class BabyCrawling\n",
      "Process class BalanceBeam\n",
      "Process class BandMarching\n",
      "Process class BaseballPitch\n",
      "Process class Basketball\n",
      "Process class BasketballDunk\n",
      "Process class BenchPress\n",
      "Process class Biking\n",
      "Process class Billiards\n",
      "Process class BlowDryHair\n",
      "Process class BlowingCandles\n",
      "Process class BodyWeightSquats\n",
      "Process class Bowling\n",
      "Process class BoxingPunchingBag\n",
      "Process class BoxingSpeedBag\n",
      "Process class BreastStroke\n",
      "Process class BrushingTeeth\n",
      "Process class CleanAndJerk\n",
      "Process class CliffDiving\n",
      "Process class CricketBowling\n",
      "Process class CricketShot\n",
      "Process class CuttingInKitchen\n",
      "Process class Diving\n",
      "Process class Drumming\n",
      "Process class Fencing\n",
      "Process class FieldHockeyPenalty\n",
      "Process class FloorGymnastics\n",
      "Process class FrisbeeCatch\n",
      "Process class FrontCrawl\n",
      "Process class GolfSwing\n",
      "Process class Haircut\n",
      "Process class HammerThrow\n",
      "Process class Hammering\n",
      "Process class HandstandPushups\n",
      "Process class HandstandWalking\n",
      "Process class HeadMassage\n",
      "Process class HighJump\n",
      "Process class HorseRace\n",
      "Process class HorseRiding\n",
      "Process class HulaHoop\n",
      "Process class IceDancing\n",
      "Process class JavelinThrow\n",
      "Process class JugglingBalls\n",
      "Process class JumpRope\n",
      "Process class JumpingJack\n",
      "Process class Kayaking\n",
      "Process class Knitting\n",
      "Process class LongJump\n",
      "Process class Lunges\n",
      "Process class MilitaryParade\n",
      "Process class Mixing\n",
      "Process class MoppingFloor\n",
      "Process class Nunchucks\n",
      "Process class ParallelBars\n",
      "Process class PizzaTossing\n",
      "Process class PlayingCello\n",
      "Process class PlayingDaf\n",
      "Process class PlayingDhol\n",
      "Process class PlayingFlute\n",
      "Process class PlayingGuitar\n",
      "Process class PlayingPiano\n",
      "Process class PlayingSitar\n",
      "Process class PlayingTabla\n",
      "Process class PlayingViolin\n",
      "Process class PoleVault\n",
      "Process class PommelHorse\n",
      "Process class PullUps\n",
      "Process class Punch\n",
      "Process class PushUps\n",
      "Process class Rafting\n",
      "Process class RockClimbingIndoor\n",
      "Process class RopeClimbing\n",
      "Process class Rowing\n",
      "Process class SalsaSpin\n",
      "Process class ShavingBeard\n",
      "Process class Shotput\n",
      "Process class SkateBoarding\n",
      "Process class Skiing\n",
      "Process class Skijet\n",
      "Process class SkyDiving\n",
      "Process class SoccerJuggling\n",
      "Process class SoccerPenalty\n",
      "Process class StillRings\n",
      "Process class SumoWrestling\n",
      "Process class Surfing\n",
      "Process class Swing\n",
      "Process class TableTennisShot\n",
      "Process class TaiChi\n",
      "Process class TennisSwing\n",
      "Process class ThrowDiscus\n",
      "Process class TrampolineJumping\n",
      "Process class Typing\n",
      "Process class UnevenBars\n",
      "Process class VolleyballSpiking\n",
      "Process class WalkingWithDog\n",
      "Process class WallPushups\n",
      "Process class WritingOnBoard\n",
      "Process class YoYo\n"
     ]
    }
   ],
   "source": [
    "trainData = []\n",
    "trainLabels = []\n",
    "trainLabelsNames = {}\n",
    "testData = []\n",
    "testLabels = []\n",
    "\n",
    "for k, classFolderName in enumerate(sorted(os.listdir(ucfPath))):\n",
    "    print('Process class ' + classFolderName)\n",
    "    trainLabelsNames[classFolderName] = k\n",
    "    for i, videoName in enumerate(sorted(os.listdir(os.path.join(ucfPath, classFolderName)))):\n",
    "        if i >= maxVideoPerClass:\n",
    "            break\n",
    "                    \n",
    "        if i == 0:\n",
    "            testLabels.append(k)\n",
    "            testData.append(np.zeros((framesPerVideo, 3, 240, 320), dtype = np.float32))\n",
    "        else:\n",
    "            trainLabels.append(k)\n",
    "            trainData.append(np.zeros((framesPerVideo, 3, 240, 320), dtype = np.float32))\n",
    "\n",
    "        count = 0\n",
    "        video = cv2.VideoCapture(os.path.join(ucfPath, classFolderName, videoName))\n",
    "        numberOfFrames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        for j in range(framesPerVideo):\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "            success, image = video.read()\n",
    "            if i == 0:\n",
    "                testData[-1][j] = np.swapaxes(\n",
    "                                       np.swapaxes(image, \n",
    "                                           0, 2),\n",
    "                                       1, 2)\n",
    "            else:\n",
    "                trainData[-1][j] = np.swapaxes(\n",
    "                                       np.swapaxes(image, \n",
    "                                           0, 2),\n",
    "                                       1, 2)\n",
    "            count += numberOfFrames // framesPerVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunc = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdvancedTimeSformer(\n",
       "  (to_patch_embedding): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (pos_emb): Embedding(4001, 64)\n",
       "  (layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_out): Sequential(\n",
       "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=64, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnable params: 644069\n",
      "Epoch: 1 Train loss: 0.607 Val loss: 0.555\n",
      "119.85035634040833 seconds for epoch\n",
      "Epoch: 2 Train loss: 0.586 Val loss: 0.546\n",
      "120.83449792861938 seconds for epoch\n",
      "Epoch: 3 Train loss: 0.568 Val loss: 0.508\n",
      "119.89849901199341 seconds for epoch\n",
      "Epoch: 4 Train loss: 0.536 Val loss: 0.493\n",
      "122.3320004940033 seconds for epoch\n",
      "Epoch: 5 Train loss: 0.519 Val loss: 0.480\n",
      "120.68999934196472 seconds for epoch\n",
      "Epoch: 6 Train loss: 0.500 Val loss: 0.464\n",
      "120.19100046157837 seconds for epoch\n",
      "Epoch: 7 Train loss: 0.476 Val loss: 0.440\n",
      "120.33250045776367 seconds for epoch\n",
      "Epoch: 8 Train loss: 0.452 Val loss: 0.420\n",
      "120.9659993648529 seconds for epoch\n",
      "Epoch: 9 Train loss: 0.418 Val loss: 0.388\n",
      "120.12649965286255 seconds for epoch\n",
      "Epoch: 10 Train loss: 0.372 Val loss: 0.390\n",
      "120.2930006980896 seconds for epoch\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('Learnable params: ' + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "    start_time = time.time()\n",
    "    indices = [i for i in range(len(trainData))]\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    #Train\n",
    "    train_loss = 0.0\n",
    "    for batchNumber in range(len(trainData) // batchSize):\n",
    "        inputs = torch.tensor([trainData[i] for i in indices[batchNumber * batchSize : (batchNumber + 1) * batchSize]]) / 255.0\n",
    "        labels = torch.tensor([trainLabels[i] for i in indices[batchNumber * batchSize : (batchNumber + 1) * batchSize]])\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunc(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    indices = [i for i in range(len(testData))]\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    #Validation\n",
    "    val_loss = 0.0\n",
    "    for batchNumber in range(len(testData) // batchSize):\n",
    "        inputs = torch.tensor([testData[i] for i in indices[batchNumber * batchSize : (batchNumber + 1) * batchSize]]) / 255.0\n",
    "        labels = torch.tensor([testLabels[i] for i in indices[batchNumber * batchSize : (batchNumber + 1) * batchSize]])\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunc(outputs, labels)\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    print('Epoch: %d Train loss: %.3f Val loss: %.3f' %\n",
    "          (epoch + 1, train_loss / len(trainData), val_loss / len(testData)))\n",
    "    \n",
    "    print(\"%s seconds for epoch\" % (time.time() - start_time))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
